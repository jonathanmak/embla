@inproceedings{Austin:1992:DynamicDependencyAnalysis,
  author       = {Todd M. Austin and Gurindar S. Sohi},
  title	       = {Dynamic dependency analysis of ordinary programs},
  booktitle    = {ISCA '92: Proceedings of the 19th annual international
                  symposium on Computer architecture},
  year	       = {1992},
  isbn	       = {0-89791-509-7},
  pages	       = {342--351},
  location     = {Queensland, Australia},
  url	       = {http://doi.acm.org/10.1145/139669.140395},
  publisher    = {ACM Press},
  address      = {New York, NY, USA},
  annote       = {A tool for dynamic data dependency analysis in order to
                  evaulate instruction-level parallelism in ordinary
                  programs (SPEC), with the intent to provide information
                  for processor design},
}

@article{Bacon:1994:CompilerTransformation,
  author       = {David F. Bacon and Susan L. Graham and Oliver J. Sharp},
  title	       = {Compiler transformations for high-performance computing},
  journal      = {ACM Comput. Surv.},
  volume       = {26},
  number       = {4},
  year	       = {1994},
  issn	       = {0360-0300},
  pages	       = {345--420},
  url	       = {http://doi.acm.org/10.1145/197405.197406},
  publisher    = {ACM Press},
  address      = {New York, NY, USA},
  annote       = {Survey of compiler transformations, including dependency
                  analysis.},
}

@inproceedings{ frigo98implementation,
    author = "Matteo Frigo and Charles E. Leiserson and Keith H. Randall",
    title = "The Implementation of the {Cilk-5} Multithreaded Language",
    booktitle = "{SIGPLAN} Conference on Programming Language Design and 
                  Implementation",
    pages = "212-223",
    year = "1998",
    url = "citeseer.ist.psu.edu/frigo98implementation.html" 
}

@inproceedings{93590,
 author = {V. Sarkar},
 title = {Instruction reordering for fork-join parallelism},
 booktitle = {PLDI '90: Proceedings of the ACM SIGPLAN 1990 
             conference on Programming language design and implementation},
 year = {1990},
 isbn = {0-89791-364-7},
 pages = {322--336},
 location = {White Plains, New York, United States},
 doi = {http://doi.acm.org/10.1145/93542.93590},
 publisher = {ACM Press},
 address = {New York, NY, USA},
 }

@article{KAB03,
  x-author =	 {Nam Sung Kim and Todd Austin and David Blaauw and
                  Trevor Mudge and Kriszti{\'a}n Flautner and Jie
                  S. Hu and Mary Jane Irwin and Mahmut Kandemir and
                  Vijaykrishnan Narayanan},
  x-author =	 {N. Kim and T. Austin and D. Blaauw and T. Mudge and
                  K. Flautner and J. Hu and M. Irwin and M. Kandemir
                  and V. Narayanan},
  author =	 {{N. Kim \textit{et al.}}},
  title =	 {Leakage Current: {Moore's Law} Meets Static Power},
  journal =	 {{IEEE} Computer},
  year =	 {2003},
  month =	 dec,
  volume =	 {36},
  number =	 {12},
  pages =	 {68--75},
  x-location =	 {kim-MPstaticPower.pdf.gz}
}

@inproceedings{TEL95,
  author =	 {D. Tullsen and S. Eggers and H. Levy},
  title =	 {Simultaneous Multithreading: Maximizing On-Chip
                  Parallelism},
  booktitle =	 {The $22^{th}$ Annual Int. Symp. on
                  Computer Architecture},
  pages =	 {392--403},
  crossref =	 {ISCA95},
  x-location =	 {levy-onchip-par.pdf.gz}
}

@proceedings{ISCA95,
   key = {ISCA95},
   title = {The $22^{th}$ Annual International Symposium on Computer
		 Architecture},
   x-month = jun # " 22--24 ",
   x-address = {Santa Margherita Ligure, Italy},
   x-publisher = {ACM Press},
   year = {1995},
   x-note = not_here
}

@inproceedings{ONHWC96,
  x-author =	 {Kunle Olukotun and Basem A. Nayfeh and Lance Hammond
                  and Ken Wilson and Kunyung Chang},
  author =	 {K. Olukotun and B. Nayfeh and L. Hammond
                  and K. Wilson and K. Chang},
  title =	 {The case for a single-chip multiprocessor},
  booktitle =	 {Proceedings of the $7^{th}$ International
                  Conference on Architectural Support for Programming
                  Languages and Operating Systems},
  year =	 {1996},
  x-month =	 oct#" 1--5 ",
  isbn =	 {0-89791-767-7},
  pages =	 {2--11},
  x-address =	 {Cambridge, Massachusetts},
  publisher =	 {ACM Press},
  x-location =	 {olukotun-ASPLOSVII.pdf.gz}
}

@article{Sutter05,
  author =	 {Herb Sutter},
  title =	 {The Free Lunch Is Over: A Fundamental Turn Toward
                  Concurrency in Software},
  journal =	 {Dr. Dobb's Journal},
  year =	 {2005},
  volume =	 {30},
  number =	 {3},
  month =	 mar,
  x-location =	 {concurrency-ddj.html.gz}
}

@article{BJKLR96,
  author =	 {R. Blumofe and C. Joerg and B. Kuszmaul and
                  C. Leiserson and K. Randall and Y. Zhou},
  title =	 {{Cilk}: An Efficient Multithreaded Runtime System},
  journal =	 {Journal of Parallel and Distributed Comuting},
  volume =	 {37},
  number =	 {1},
  pages =	 {55--69},
  month =	 aug,
  year =	 {1996}
}

@inproceedings{AS92,
  x-author =	 {Todd M. Austin and Gurindar S. Sohi},
  author =	 {T. Austin and G. Sohi},
  title =	 {Dynamic dependency analysis of ordinary programs},
  booktitle =	 {ISCA'92: Proceedings of the 19$^{th}$ Annual
                  International Symposium on Computer Architecture},
  year =	 {1992},
  isbn =	 {0-89791-509-7},
  pages =	 {342--351},
  address =	 {Queensland, Australia},
  publisher =	 {ACM Press},
  x-location =	 {austin-dda-op.pdf.gz}
}

@article{LF00,
   author = {D.K. Lowenthal and V.W. Freeh},
   title = {Architecture-independent parallelism for both shared-
            and distributed-memory machines using the {Filaments} package},
   journal = {Parallel Computing},
   x-volume = {26},
   x-number = {10},
   x-pages = {1297--1323},
   month = aug,
   year = {2000},
   ISSN = {0167-8191},
   x-annotation = {The guys are dealing with architecture-independent
                   parallel programming. The package abstracts away
                   the real number of processors, and allows
                   programmers to specify parallelism as it fits the
                   application. It also abstracts away the properties
                   of interconnections, e.g. shared-memory and
                   message-passing architectures; it provides for a
                   shared-variable communication. A filament is a very
                   lightweight thread. The paper has a good "related
                   work" section.},
   x-note = {I have a preliminary version (dated July 15, 1998).}
}

@inproceedings{Lea00,
  x-author =	 {Doug Lea},
  author =	 {D. Lea},
  title =	 {A {Java} fork/join framework},
  booktitle =	 {JAVA '00: Proceedings of the ACM 2000 conference on
                  Java Grande},
  year =	 {2000},
  isbn =	 {1-58113-288-3},
  pages =	 {36--43},
  location =	 {San Francisco, California, United States},
  publisher =	 {ACM Press},
  address =	 {New York},
  x-location =	 {lea-java-forkjoin.pdf.gz}
}

@inproceedings{Rinard01,
  author =	 {Martin C. Rinard},
  title =	 {Analysis of Multithreaded Programs},
  booktitle =	 {SAS '01: Proceedings of the 8th International
                  Symposium on Static Analysis},
  year =	 {2001},
  isbn =	 {3-540-42314-1},
  pages =	 {1--19},
  publisher =	 {Springer-Verlag},
  address =	 {London, UK},
  x-locatino =	 {rinard-analysis.ps.gz}
}

@inproceedings{NAW06,
  x-author =	 {Mayur Naik and Alex Aiken and John Whaley},
  author =	 {M. Naik and A. Aiken and J. Whaley},
  title =	 {Effective static race detection for Java},
  booktitle =	 {PLDI 06: Proceedings of the ACM SIGPLAN 2006
                  Conference on Programming Language Design and
                  Implementation},
  note =	 {SIGPLAN Notices 41(6).},
  year =	 {2006},
  month =	 jun#" 10--16 ",
  issn =	 {0362-1340},
  pages =	 {308--319},
  publisher =	 {ACM Press},
  address =	 {Ottawa, Ontario, Canada},
  abstract =	 {We present a novel technique for static race
                  detection in Java programs, comprised of a series of
                  stages that employ a combination of static analyses
                  to successively reduce the pairs of memory accesses
                  potentially involved in a race. We have implemented
                  our technique and applied it to a suite of
                  multi-threaded Java programs. Our experiments show
                  that it is precise, scalable, and useful, reporting
                  tens to hundreds of serious and previously unknown
                  concurrency bugs in large, widely-used programs with
                  few false alarms.},
  x-annotation = {Including a (large) survey of related approaches,
                  including dynamic race detection (using the
                  Lamport's "happens-before" relation, atomicity
                  checking and combination thereof), static race
                  detection (flow insensitive type-based systems, flow
                  sensitive static versions of the lockset algorithm
                  (Warlock and RacerX), or path sensitive model
                  checkers), and atomicity checking.},
  x-location =	 {naik-esrd4java.pdf.gz}
}

@article{Rauchwerger98,
  x-author =	 {Lawrence Rauchwerger},
  author =	 {L. Rauchwerger},
  title =	 {Run-time parallelization: {It's} time has come},
  journal =	 {Parallel Computing},
  volume =	 {24},
  number =	 {3--4},
  pages =	 {527--556},
  year =	 {1998},
  x-location =	 {rauchwerger-rt-p.pdf.gz}
}


@inproceedings{MellorCrummey91,
  x-author =	 {John Mellor-Crummey},
  author =	 {J. Mellor-Crummey},
  title =	 {On-the-fly detection of data races for programs with
                  nested fork-join parallelism},
  booktitle =	 {Proceedings of Supercomputing '91},
  pages =	 {24--33},
  year =	 {1991},
  publisher =	 {ACM Press},
  isbn =	 {0-89791-459-7},
  x-location =	 {mc-ontf-dr-fjp.pdf.gz}
}

@inproceedings{HRY02,
  x-author =	 {Keum-Sook Ha and Eun-Kyung Ryu and Kee-Young Yoo},
  author =	 {K.-S. Ha and E.-K. Ryu and K.-Y. Yoo},
  title =	 {Space-Efficient First Race Detection in Shared
                  Memory Programs with Nested Parallelism},
  year =	 {2002},
  pages =	 {253-263},
  editor =	 {Juha Fagerholm and Juha Haataja and Jari
                  J{\"a}rvinen and Mikko Lyly and Peter R{\aa}back and
                  Ville Savolainen},
  booktitle =	 {Applied Parallel Computing Advanced Scientific
                  Computing, 6th International Conference (PARA 2002)},
  address =	 {Espoo, Finland},
  month =	 jun#" 15--18 ",
  publisher =	 {Springer},
  series =	 {LNCS},
  volume =	 {2367},
  isbn =	 {3-540-43786-X},
  x-note =	 not_here
}

@article{SBNSA97,
  x-author =	 {Stefan Savage and Michael Burrows and Greg Nelson
                  and Patrick Sobalvarro and Thomas Anderson},
  author =	 {S. Savage and M. Burrows and G. Nelson and
                  P. Sobalvarro and T. Anderson},
  title =	 {Eraser: a dynamic data race detector for
                  multithreaded programs},
  journal =	 {ACM Transactions on Computer Systems},
  volume =	 {15},
  number =	 {4},
  year =	 {1997},
  issn =	 {0734-2071},
  pages =	 {391--411},
  publisher =	 {ACM Press},
  address =	 {New York, NY, USA},
  abstract =	 {Multithreaded programming is difficult and error
                  prone. It is easy to make a mistake in
                  synchronization that produces a data race, yet it
                  can be extremely hard to locate this mistake during
                  debugging. This article describes a new tool, called
                  Eraser, for dynamically detecting data races in
                  lock-based multithreaded programs. Eraser uses
                  binary rewriting techniques to monitor every
                  shared-monory reference and verify that consistent
                  locking behavior is observed. We present several
                  case studies, including undergraduate coursework and
                  a multithreaded Web search engine, that demonstrate
                  the effectiveness of this approach.},
  x-location =	 {savage-eraser.pdf.gz}
}

@inproceedings{PO03,
  x-author =	 {Manohar K. Prabhu and Kunle Olukotun},
  author =	 {M. Prabhu and K. Olukotun},
  title =	 {Using thread-level speculation to simplify manual
                  parallelization},
  booktitle =	 {Proceedings of the $9^{th}$ ACM SIGPLAN Symp. on
                  Principles and Practice of Parallel Programming},
  year =	 {2003},
  isbn =	 {1-58113-588-2},
  x-pages =	 {1--12},
  x-address =	 {San Diego, California, USA},
  x-publisher =	 {ACM Press},
  abstract =	 {In this paper, we provide examples of how
                  thread-level speculation (TLS) simplifies manual
                  parallelization and enhances its performance. A
                  number of techniques for manual parallelization
                  using TLS are presented and results are provided
                  that indicate the performance contribution of each
                  technique on seven SPEC CPU2000 benchmark
                  applications. We also provide indications of the
                  programming effort required to parallelize each
                  benchmark. TLS parallelization yielded a 110%
                  speedup on our four floating point applications and
                  a 70% speedup on our three integer applications,
                  while requiring only approximately 80 programmer
                  hours and 150 lines of non-template code per
                  application. These results support the idea that
                  manual parallelization using TLS is an efficient way
                  to extract fine-grain thread-level parallelism.},
  x-location =	 {prabhu-usingTLS.pdf.gz}
}

@article{RS01b,
  author =	 {Peter Rundberg and Per Stenstr{\"o}m},
  title =	 {An All-Software Thread-Level Data Dependence
                  Speculation System for Multiprocessors},
  journal =	 {J. Instruction-Level Parallelism},
  volume =	 {3},
  year =	 {2001},
  x-location =	 {rundberg-jilp.pdf.gz}
}

@article{ABL97,
  x-author =	 {Glenn Ammons and Thomas Ball and James R. Larus},
  author =	 {G. Ammons and T. Ball and J. Larus},
  title =	 {Exploiting hardware performance counters with flow
                  and context sensitive profiling},
  journal =	 {ACM SIGPLAN Notices},
  volume =	 {32},
  number =	 {5},
  year =	 {1997},
  issn =	 {0362-1340},
  pages =	 {85--96},
  publisher =	 {ACM Press},
  address =	 {New York, NY, USA},
  abstract =	 {A program profile attributes run-time costs to
                  portions of a program's execution. Most profiling
                  systems suffer from two major deficiencies: first,
                  they only apportion simple metrics, such as
                  execution frequency or elapsed time to static,
                  syntactic units, such as procedures or statements;
                  second, they aggressively reduce the volume of
                  information collected and reported, although
                  aggregation can hide striking differences in program
                  behavior.This paper addresses both concerns by
                  exploiting the hardware counters available in most
                  modern processors and by incorporating two concepts
                  from data flow analysis--flow and context
                  sensitivity--to report more context for
                  measurements. This paper extends our previous work
                  on efficient path profiling to flow sensitive
                  profiling, which associates hardware performance
                  metrics with a path through a procedure. In
                  addition, it describes a data structure, the calling
                  context tree, that efficiently captures calling
                  contexts for procedure-level measurements.Our
                  measurements show that the SPEC95 benchmarks execute
                  a small number (3--28) of hot paths that account for
                  9--98% of their L1 data cache misses. Moreover,
                  these hot paths are concentrated in a few routines,
                  which have complex dynamic behavior.},
  x-annotation = {CFG, DCT, DCG, CCT},
  x-location =	 {ammons-profiling.ps.gz ammons-profiling.pdf.gz}
}

@article{GF64,
 author = {Benrard A. Galler and Michael J. Fisher},
 title = {An improved equivalence algorithm},
 journal = {Commun. ACM},
 volume = {7},
 number = {5},
 year = {1964},
 issn = {0001-0782},
 pages = {301--303},
 doi = {http://doi.acm.org/10.1145/364099.364331},
 publisher = {ACM Press},
 address = {New York, NY, USA},
 }

@inproceedings{Conway63,
  author =	 {M. Conway},
  title =	 {A multiprocessor system design},
  booktitle =	 {Proceedings of AFIPS FJCC'63},
  pages =	 {139-148},
  year =	 {1963},
  volume =	 {24},
  x-address =	 {Las Vegas, USA},
  x-month =	 nov,
  publisher =	 {Spartan Books},
  x-annotation = {The fork/join framework.},
  x-note =	 not_here
}

@article{VIAVAC05,
  x-author =	 {Neil Vachharajani and Matthew Iyer and Chinmay Ashok
                  and Manish Vachharajani and David I. August and
                  Daniel A. Connors},
  author =	 {N. Vachharajani and M. Iyer and C. Ashok and
                  M. Vachharajani and D. August and D. Connors},
  title =	 {Chip multi-processor scalability for single-threaded
                  applications},
  journal =	 {SIGARCH Computer Architecture News},
  volume =	 {33},
  number =	 {4},
  year =	 {2005},
  issn =	 {0163-5964},
  pages =	 {44--53},
  abstract =	 {The exponential increase in uniprocessor performance
                  has begun to slow. Designers have been unable to
                  scale performance while managing thermal, power, and
                  electrical effects. Furthermore, design complexity
                  limits the size of monolithic processors that can be
                  designed while keeping costs reasonable. Industry
                  has responded by moving toward chip multi-processor
                  architectures (CMP). These architectures are
                  composed from replicated processors utilizing the
                  die area afforded by newer design processes. While
                  this approach mitigates the issues with design
                  complexity, power, and electrical effects, it does
                  nothing to directly improve the performance of
                  contemporary or future single-threaded
                  applications.This paper examines the scalability
                  potential for exploiting the parallelism in
                  single-threaded applications on these CMP
                  platforms. The paper explores the total available
                  parallelism in unmodified sequential applications
                  and then examines the viability of exploiting this
                  parallelism on CMP machines. Using the results from
                  this analysis, the paper forecasts that CMPs, using
                  the "intrinsic" parallelism in a program, can
                  sustain the performance improvement users have come
                  to expect from new processors for only 6-8 years
                  provided many successful parallelization efforts
                  emerge. Given this outlook, the paper advocates
                  exploring methodologies which achieve parallelism
                  beyond this "intrinsic" limit of programs.},
  x-location =	 {vachharajani-cmp-s-sta.pdf.gz}
}

@book{KA02,
  author =	 {Ken Kennedy and John R. Allen},
  title =	 {Optimizing Compilers for Modern Architectures: a
                  Dependence-Based Approach},
  year =	 {2002},
  isbn =	 {1-55860-286-0},
  publisher =	 {Morgan Kaufmann Publishers Inc.},
  address =	 {San Francisco, CA, USA},
}



@Misc{MPEG,
  key	       = {Reference {MPEG-2} video codec software},
  author       = {{MPEG} software simulation group},
  title	       = {Reference {MPEG-2} video codec software},
  howpublished = {http://www.mpeg.org/MPEG/MSSG/},
}

@article{CL03,
  x-author =	 {Marcelo Cintra and Diego R. Llanos},
  author =	 {M. Cintra and D. Llanos},
  title =	 {Toward efficient and robust software speculative
                  parallelization on multiprocessors},
  journal =	 {Proceedings of the ACM
                  SIGPLAN Symposium on Principles and Practice of
                  Parallel Programming},
  volume =	 {38},
  number =	 {10},
  year =	 {2003},
  issn =	 {0362-1340},
  pages =	 {13--24},
  x-publisher =	 {ACM Press},
  x-location =	 {cintra-er-ssp.pdf.gz}
}

@article{DM98,
  x-author =	 {Leonardo Dagum and Ramesh Menon},
  author =	 {L. Dagum and R. Menon},
  title =	 {{OpenMP}: An Industry-Standard {API} for Shared-Memory
                  Programming},
  journal =	 {IEEE Computational Science \& Engineering},
  volume =	 {5},
  number =	 {1},
  year =	 {1998},
  issn =	 {1070-9924},
  pages =	 {46--55},
  publisher =	 {IEEE Computer Society Press},
  x-location =	 {dagum-openmp.pdf.gz}
}
