\section{Introduction}

Parallel programming is no longer optional.  In order to enjoy continued
performance gains with future generation multi-core processors,
application developers must parallelize all software, old and
new.
% \cite{TEL95,ONHWC96,KAB03,VIAVAC05}
%.  
% For scalable parallel
% performance, program execution must be divided into large numbers of
% independent tasks that can be scheduled on available cores and hardware
% threads by runtime systems.  
While automatic parallelization based on static analysis 
% \cite{KA02}
is sometimes feasible, currently most software requires manual
parallelization.
Since this is a difficult task, there is urgent need for efficient tool support---in
particular, tools that assist the programmer in understanding the potential 
for parallelization in the code, parallelizing code with high potential, 
and validating that the resulting parallel code is correct.

In this paper, we address the first two issues by presenting a tool
which, when given a sequential program and an input, can estimate the 
amount of parallelism that would be available if the program was parallelized
using language constructs such as those in OpenMP~\cite{dagum98openmp}
or Cilk~\cite{blumofe96cilk}. We validate our results against timing 
measurements of explicitly parallel Cilk programs.

To estimate potential parallelism of programs written
in a sequential language, the tool must construct
an {\em estimated parallelization}. This requires two kinds of information:
\begin{itemize}
\item
Information about the program, in particular about the dependences between 
different parts, since these determine which parallelization is legal.
\item
Information about the parallel execution mechanisms and how these are going
to be integrated into the program, that is, what parallelizing transformations 
may be used.
\end{itemize}
We have implemented a parallelism measurement tool by extending
Embla \cite{embla:08}, a tool which captures dependence information by 
profiling a program, with functionality for simulating the effects of various parallel 
programming models, all based on independent fork-join task parallelism,
%\cite{Conway63}
a framework used in many parallel programming environments.
%\cite{BJKLR96, Lea00, DM98, LF00}.

Unlike traditional studies of parallelism limits \cite{wall91limits,warg01limits}
which focus on hardware parameters, we focus on the 
parallelization of program source code, and so use a
different set of parameters to vary and different constraints for
parallelization. The aim is to address the question,
``Will techniques such as
Thread-level speculation or parallel for-loops make much
difference to the possible speed-up when parallelizing
a program?'' Section~\ref{smethod} 
discusses our parallelization models in depth.

We have used our prototype tool to investigate the potential for 
parallelization of three collections of programs; the SPEC CPU 2000 
integer programs, MiBench and the example programs in
the Cilk 5.4.6 distribution. While the first two collections contain
sequential programs, the last one is made up of explicitly parallel 
programs in the Cilk 5 language. These have the property that eliding
the parallel constructs leaves correct sequential code.
We can thus contrast 
programs from these different sources as well as show the behaviour of 
the different models, including the effects of control and dependence speculation.
Section~\ref{sresults} reports the results of these experiments.

The contributions can be summarised as follows:
\begin{itemize}
\item
By using Embla to map dynamic dependences back to program source,
our tool gives a realistic estimate of potential speed-up for
parallelization using frameworks such as Cilk and OpenMP.
Previous studies that we know of~\cite{Kreaseck00limitsof,warg01limits,oplinger99insearch}
have only considered \emph{speculative}
task-level parallelism---we give potential speed-ups for programs
both with and without the use of thread-level speculation.
Using this tool we present estimates of inherent parallelism in
serial elisions of example Cilk programs (Section~\ref{sresults:cilk}).
\item
Dependences output by Embla assist the programmer in 
parallelizing program source by identifying
appropriate synchronization points. We show how synchronization
points identified in serial elisions of example Cilk programs
match those in the original programs (Section~\ref{sresults:cilk}).
\item
Critical paths output by our tool can
be used to identify bottlenecks that restrict the level of
inherent parallelism. We illustrate this using examples
from the MiBench benchmark suite, and suggest refactorings
or algorithmic changes to increase potential parallelism (Section~\ref{sresults:increasing}).
\end{itemize}
